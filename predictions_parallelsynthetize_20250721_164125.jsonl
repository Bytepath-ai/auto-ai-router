{"instance_id": "astropy__astropy-12907", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -1,4 +1,5 @@\n # Licensed under a 3-clause BSD style license - see LICENSE.rst\n+\n \"\"\"\n This module is concerned with the separability of models.\n \"\"\"\n@@ -7,79 +8,44 @@\n from .core import CompoundModel, Model\n \n \n-def _separable(transform):\n-    \"\"\"\n-    This is the engine for `separability_matrix`.\n-\n-    It is a recursive function which goes down the tree of\n-    a composite model and determines the separability matrix.\n-    \"\"\"\n-    if not transform.separable:\n-        return np.ones((transform.n_outputs, transform.n_inputs), dtype=bool)\n-    elif isinstance(transform, CompoundModel):\n-        sepleft = _separable(transform.left)\n-        sepright = _separable(transform.right)\n-        return _operators[transform.op](sepleft, sepright)\n-    elif isinstance(transform, Model):\n-        return _coord_matrix(transform, \"left\", transform.n_outputs)\n-\n-\n-def _coord_matrix(transform, side, n):\n-    \"\"\"\n-    Helper function to create a matrix with 1s and 0s representing\n-    input to output mapping.\n-    \"\"\"\n-    if transform.separable:\n-        return np.eye(n, M=getattr(transform, \"n_inputs\"), dtype=bool)\n-    else:\n-        return np.ones((n, getattr(transform, \"n_inputs\")), dtype=bool)\n-\n-\n-def _cstack(left, right):\n-    \"\"\"\n-    Function corresponding to \"|\" operation.\n-\n-    Parameters\n-    ----------\n-    left : model\n-        Left operand of the composition.\n-    right : model\n-        Right operand of the composition.\n-    \"\"\"\n-    if not isinstance(left, np.ndarray):\n-        cleft = _coord_matrix(left, \"left\", left.n_outputs)\n-    else:\n-        cleft = left\n-    if not isinstance(right, np.ndarray):\n-        cright = _coord_matrix(right, \"right\", right.n_outputs)\n-    else:\n-        cright = right\n-    result = np.dot(cleft, cright)\n-    return result.astype(bool)\n-\n-\n-def _cdot(left, right):\n-    \"\"\"\n-    Function corresponding to \"&\" operation.\n-\n-    Parameters\n-    ----------\n-    left : model\n-        Left operand.\n-    right : model\n-        Right operand.\n-    \"\"\"\n-    if not isinstance(left, np.ndarray):\n-        cleft = _coord_matrix(left, \"left\", left.n_outputs)\n-    else:\n-        cleft = left\n-    if not isinstance(right, np.ndarray):\n-        cright = _coord_matrix(right, \"right\", right.n_outputs)\n-    else:\n-        cright = right\n-    result = np.block(\n-        [\n-            [cleft, np.zeros((cleft.shape[0], cright.shape[1]), dtype=bool)],\n-            [np.zeros((cright.shape[0], cleft.shape[1]), dtype=bool), cright],\n-        ]\n-    )\n-    return result\n-\n-\n-_operators = {\"&\": _cdot, \"|\": _cstack, \"+\": _cstack, \"-\": _cstack}\n-\n-\n def separability_matrix(transform):\n     \"\"\"\n     Return the separability matrix of a model.\n@@ -90,4 +56,43 @@\n     sepa_matrix : `numpy.ndarray`\n         A `(model.n_outputs, model.n_inputs)` boolean matrix.\n     \"\"\"\n-    return _separable(transform)\n+    if isinstance(transform, CompoundModel):\n+        if transform.op == \"&\":\n+            # block diagonal\n+            m1_sepa = separability_matrix(transform.left)\n+            m2_sepa = separability_matrix(transform.right)\n+            matrix = np.block(\n+                [\n+                    [\n+                        m1_sepa,\n+                        np.zeros(\n+                            (transform.left.n_outputs, transform.right.n_inputs),\n+                            dtype=bool,\n+                        ),\n+                    ],\n+                    [\n+                        np.zeros(\n+                            (transform.right.n_outputs, transform.left.n_inputs),\n+                            dtype=bool,\n+                        ),\n+                        m2_sepa,\n+                    ],\n+                ]\n+            )\n+            return matrix\n+        elif transform.op == \"|\":\n+            # matrix multiplication\n+            m1_sepa = separability_matrix(transform.left)\n+            m2_sepa = separability_matrix(transform.right)\n+            return np.dot(m2_sepa, m1_sepa).astype(bool)\n+        else:  # All other operators (+, -, *, /, **) combine outputs\n+            m1_sepa = separability_matrix(transform.left)\n+            m2_sepa = separability_matrix(transform.right)\n+            return m1_sepa | m2_sepa\n+    elif not transform.separable:\n+        return np.ones((transform.n_outputs, transform.n_inputs), dtype=bool)\n+    else:\n+        sepa = transform.separable\n+        if sepa is True:\n+            return np.eye(transform.n_outputs, M=transform.n_inputs, dtype=bool)\n+        return sepa\n\n```"}
{"instance_id": "astropy__astropy-14182", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -1,6 +1,7 @@\n # Licensed under a 3-clause BSD style license - see LICENSE.rst\n \"\"\"An extensible ASCII table reader and writer.\n \"\"\"\n+\n import re\n \n from . import core, fixedwidth\n@@ -65,6 +66,7 @@\n         \"\"\"\n         names = kwargs.pop(\"names\", ())\n         include_names = kwargs.pop(\"include_names\", ())\n+        header_rows = kwargs.pop(\"header_rows\", [\"name\"])\n         exclude_names = kwargs.pop(\"exclude_names\", ())\n         tabletype = kwargs.pop(\"tabletype\", \"table\")\n         backend = kwargs.pop(\"backend\", \"ascii\")\n@@ -74,6 +76,7 @@\n             self, delimiter_pad=\" \", names=names, include_names=include_names,\n             exclude_names=exclude_names, **kwargs\n         )\n+        self.header_rows = header_rows\n         self.header = RSTHeader()\n         self.header.splitter.delimiter = \"=\"\n         self.data = RSTData()\n@@ -91,15 +94,22 @@\n         # data strings to use for output.\n         with capture_stdout() as fw_output:\n             fixedwidth.FixedWidth.write(self, lines)\n-        fw_output_lines = fw_output.getvalue().strip().split(\"\\n\")\n-        # First line is the column headers\n-        separator_line = re.sub(r\".\", \"=\", fw_output_lines[0].strip())\n+        fw_output_lines = [x for x in fw_output.getvalue().split(\"\\n\") if x.strip()]\n+        if not fw_output_lines:\n+            return []\n+\n+        # Create separator line based on first line width, but replace\n+        # non-whitespace with '='.\n+        separator_line = re.sub(r\"\\S\", \"=\", fw_output_lines[0]).strip()\n+\n+        n_header_lines = len(self.header_rows)\n+\n         lines.append(separator_line)\n-        lines.append(fw_output_lines[0].strip())\n+        for i in range(n_header_lines):\n+            lines.append(fw_output_lines[i].strip())\n         lines.append(separator_line)\n-        lines.extend([line.strip() for line in fw_output_lines[1:]])\n+        lines.extend([line.strip() for line in fw_output_lines[n_header_lines:]])\n         lines.append(separator_line)\n \n         if self.tabletype == \"directive\":\n\n```"}
{"instance_id": "astropy__astropy-14365", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -59,7 +59,7 @@\n         _new_re = rf\"NO({sep}NO)+\"\n         _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan))*)\"\n         _type_re = rf\"^\\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?\\s*(\\!(?P<comment>.*))?\\s*$\"\n-        _line_type_re = re.compile(_type_re)\n+        _line_type_re = re.compile(_type_re, re.IGNORECASE)\n         _line_type_re_cache[sep] = _line_type_re\n     line = line.strip()\n     if not line:\n@@ -275,7 +275,7 @@\n \n         command = line_dict[\"command\"]\n         if command is not None:\n-            _interpret_err_lines(command, lines, line_nos)\n+            _interpret_err_lines(command.upper(), lines, line_nos)\n         elif line_dict[\"new\"] is not None:\n             if current_rows is not None and len(current_rows) > 0:\n                 _finalize_previous_table(\n\n```"}
{"instance_id": "astropy__astropy-14995", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/astropy/nddata/mixins/ndarithmetic.py\n+++ b/astropy/nddata/mixins/ndarithmetic.py\n@@ -495,7 +495,7 @@ class NDArithmeticMixin:\n         elif self.mask is None and operand is not None:\n             # TODO: there are other options here, ignore seems reasonable\n             return deepcopy(operand.mask)\n-        elif operand is None:\n+        elif operand.mask is None:\n             return deepcopy(self.mask)\n         else:\n             # Now lets calculate the resulting mask (operation enforces copy)\n\n```"}
{"instance_id": "astropy__astropy-6938", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/astropy/io/fits/fitsrec.py\n+++ b/astropy/io/fits/fitsrec.py\n@@ -1261,7 +1261,7 @@ class FITS_rec(np.recarray):\n \n         # Replace exponent separator in floating point numbers\n         if 'D' in format:\n-            output_field.replace(encode_ascii('E'), encode_ascii('D'))\n+            output_field[:] = output_field.replace(encode_ascii('E'), encode_ascii('D'))\n \n     def _get_recarray_field(self, key):\n         \"\"\"\n\n```"}
{"instance_id": "astropy__astropy-7746", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/astropy/wcs/wcs.py\n+++ b/astropy/wcs/wcs.py\n@@ -1213,6 +1213,11 @@\n \n     def _return_single_array(x, origin):\n \n+        # If the input is empty, return an empty array. This avoids calling\n+        # the underlying wcslib which would fail.\n+        if x.size == 0:\n+            return np.empty((0, self.naxis), dtype=np.double)\n+\n         if x.shape[-1] != self.naxis:\n             raise TypeError(\n                 \"When providing a single N-dimensional array, the \"\n@@ -1236,6 +1241,13 @@\n                     len(axes), self.naxis))\n         # Turn these into a single array of vectors\n         xy = np.vstack(axes).transpose()\n+\n+        # If the input was empty, xy will have shape (0, naxis). The C\n+        # extension will fail on this, so we return empty arrays here. This\n+        # makes calls such as ``wcs_pix2world([], [], 0)`` behave intuitively.\n+        if xy.shape[0] == 0:\n+            return [np.array([], dtype=np.double) for _ in range(self.naxis)]\n+\n         if ra_dec_order and sky == 'input':\n             xy = self._denormalize_sky(xy)\n         output = func(xy, origin)\n\n```"}
{"instance_id": "django__django-10914", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -304,9 +304,11 @@\n FILE_UPLOAD_MAX_MEMORY_SIZE = 2621440  # i.e. 2.5 MB\n \n # The numeric mode to set newly-uploaded files to. The value should be a mode\n-# you'd pass directly to os.chmod; see https://docs.python.org/library/os.html#files-and-directories.\n-FILE_UPLOAD_PERMISSIONS = None\n+# you'd pass directly to os.chmod; see https://docs.python.org/3/library/os.html#files-and-directories.\n+# The default of 0o644 gives read/write permissions to the owner and\n+# read-only permissions to the group and others, avoiding inconsistencies\n+# between files uploaded from memory and those written to temporary files.\n+# Set this to None to retain the operating system\u2019s default behavior.\n+FILE_UPLOAD_PERMISSIONS = 0o644\n \n # The numeric mode to assign to newly-created directories, when uploading files.\n # The value should be a mode as you'd pass to os.chmod;\n--- a/docs/releases/3.0.txt\n+++ b/docs/releases/3.0.txt\n@@ -6,6 +6,20 @@\n \n Backwards incompatible changes in 3.0\n ====================================\n+\n+:setting:`FILE_UPLOAD_PERMISSIONS` has a new default value\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+To avoid inconsistent behavior, the :setting:`FILE_UPLOAD_PERMISSIONS` setting\n+now defaults to ``0o644``. Previously, when this setting was ``None``,\n+uploaded files could have different permissions depending on their size: files\n+that used the\n+:class:`~django.core.files.uploadhandler.TemporaryFileUploadHandler`\n+would have permissions of ``0o600`` on some platforms, while files that used\n+the :class:`~django.core.files.uploadhandler.MemoryFileUploadHandler` would use\n+the system's umask.\n+\n+To restore the previous behavior, set :setting:`FILE_UPLOAD_PERMISSIONS` to ``None``.\n \n ``django.contrib.gis``\n ----------------------\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -1523,16 +1523,19 @@\n FILE_UPLOAD_PERMISSIONS\n -----------------------\n \n-Default: ``None``\n+.. versionchanged:: 3.0\n+    The default was changed from ``None`` to ``0o644``.\n+\n+Default: ``0o644``\n \n The numeric mode to set newly-uploaded files to. For more information about\n what these modes mean, see the documentation for :func:`os.chmod`.\n \n-If this isn't given or is ``None``, you'll get operating-system\n-dependent behavior. On most platforms, temporary files will have a mode\n-of ``0o600``, and files saved from memory will be saved using the\n-system's standard umask.\n+If this is set to ``None``, you'll get operating-system dependent behavior. On\n+most platforms, files uploaded to a temporary file on disk will have a mode of\n+``0o600``, while files uploaded to memory will be saved using the system's\n+standard umask. Explicitly setting this value avoids this inconsistent behavior\n+based on upload size.\n \n For security reasons, these permissions aren't applied to the temporary files\n that are stored in :setting:`FILE_UPLOAD_TEMP_DIR`.\n--- a/docs/topics/deployment/checklist.txt\n+++ b/docs/topics/deployment/checklist.txt\n@@ -103,13 +103,15 @@\n See :ref:`the documentation for the File object's <file-object>` ``save()``\n method for more information.\n \n-:setting:`FILE_UPLOAD_PERMISSIONS`\n-----------------------------------\n+:setting:`FILE_UPLOAD_PERMISSIONS` and :setting:`FILE_UPLOAD_DIRECTORY_PERMISSIONS`\n+----------------------------------------------------------------------------------\n \n-Some web servers (e.g. Apache) strip the ``Authorization`` header from incoming\n-requests by default. Without this header, Django can't authenticate the user.\n-To work around this, you can configure your web server to pass along the\n-header, or use ``Mod_WSGI`` :ref:`wsgi-auth-with-mod-wsgi`.\n+If your file upload handling allows users to upload files, you are strongly\n+advised to check these values. In previous Django versions, if\n+:setting:`FILE_UPLOAD_PERMISSIONS` was not set, uploaded files could receive\n+inconsistent permissions (``0o600`` or the system umask) depending on the upload\n+handler used. The default is now ``0o644`` to ensure consistent behavior. Set\n+this to ``None`` to restore the previous behavior.\n \n .. _deployment-checklist-python-options:\n \n\n```"}
{"instance_id": "django__django-10924", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1798,7 +1798,9 @@\n         ]\n \n     def _check_path(self):\n-        if self.path and not os.path.isdir(self.path):\n+        if callable(self.path):\n+            return []\n+        if self.path and not os.path.isdir(self.path):\n             return [\n                 checks.Error(\n                     \"'FilePathField.path' must be a directory.\",\n@@ -1831,8 +1833,9 @@\n         return name, path, args, kwargs\n \n     def formfield(self, **kwargs):\n+        path = self.path() if callable(self.path) else self.path\n         return super().formfield(**{\n-            'path': self.path,\n+            'path': path,\n             'match': self.match,\n             'recursive': self.recursive,\n             'allow_files': self.allow_files,\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -1088,9 +1088,11 @@\n \n     def __init__(self, path, *, match=None, recursive=False, allow_files=True,\n                  allow_folders=False, **kwargs):\n-        self.path = path\n+        if callable(path):\n+            path = path()\n+        self.path = path\n         self.match = match\n         self.recursive = recursive\n         self.allow_files = allow_files\n\n```"}
{"instance_id": "django__django-11001", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -62,7 +62,7 @@\n         self.select_aliases = set()\n         self.table_aliases = set()\n         self.found_aggregates = set()\n-        self.ordering_parts = re.compile(r'(.*)\\s+(?:ASC|DESC)\\s*$', re.IGNORECASE)\n+        self.ordering_parts = re.compile(r'(.*)\\s+(?:ASC|DESC)\\s*$', re.IGNORECASE | re.DOTALL)\n \n     @cached_property\n     def select_related_idx(self):\n\n```"}
{"instance_id": "django__django-11019", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -1,16 +1,15 @@\n import copy\n-import warnings\n-from itertools import chain\n+from collections import OrderedDict, defaultdict\n+from itertools import chain\n+import warnings\n \n from django.conf import settings\n-from django.forms.utils import MediaOrderConflictWarning, flatatt\n+from django.forms.utils import flatatt\n from django.templatetags.static import static\n-from django.utils.deprecation import RemovedInDjango30Warning\n from django.utils.encoding import force_text\n from django.utils.functional import Promise\n from django.utils.html import format_html, format_html_join\n from django.utils.safestring import mark_safe\n-from django.utils.translation import gettext_lazy as _\n \n from .utils import MediaOrderConflictWarning\n \n@@ -48,19 +47,25 @@\n \n \n class Media:\n-    def __init__(self, media=None, css=None, js=None):\n+    def __init__(self, css=None, js=None):\n         if css is None:\n             css = {}\n         if js is None:\n             js = []\n+        # To simplify the handling of both lists and tuples, we standardize on\n+        # tuples.\n+        self._css = {\n+            # De-duplicate while preserving order.\n+            medium: tuple(OrderedDict.fromkeys(paths))\n+            for medium, paths in css.items()\n+        }\n+        self._js = tuple(OrderedDict.fromkeys(js))\n         # self._css_lists consists of the CSS definitions from this instance\n         # and all its children. The same applies to self._js_lists.\n         # Each list of CSS definitions is a dictionary, and each list of JS\n-        # definitions is a list.\n-        self._css_lists = [css]\n-        self._js_lists = [js]\n+        # definitions is a list or tuple.\n+        self._css_lists = [self._css] if self._css else []\n+        self._js_lists = [self._js] if self._js else []\n \n     def __repr__(self):\n         return 'Media(css=%r, js=%r)' % (self._css, self._js)\n@@ -87,20 +92,18 @@\n \n     @property\n     def _js(self):\n-        if not self._js_lists:\n-            return []\n-        # filter(None, ...) avoids calling merge() with empty lists.\n-        js = self._js_lists[0]\n-        for obj in filter(None, self._js_lists[1:]):\n-            js = self.merge(js, obj)\n-        return js\n+        return self.merge(*self._js_lists)\n \n     @property\n     def _css(self):\n-        if not self._css_lists:\n-            return {}\n-        # filter(None, ...) avoids calling merge() with empty lists.\n-        css = self._css_lists[0]\n-        for obj in filter(None, self._css_lists[1:]):\n-            css = {\n-                medium: self.merge(css.get(medium, []), css_list.get(medium, []))\n-                for medium in css.keys() | css_list.keys()\n-            }\n-        return css\n+        # The CSS media definitions are dictionaries, so they have to be\n+        # merged specially.\n+        css = defaultdict(list)\n+        for css_list in self._css_lists:\n+            for medium, paths in css_list.items():\n+                css[medium].append(paths)\n+\n+        for medium, lists in css.items():\n+            css[medium] = self.merge(*lists)\n+        return dict(css)\n \n     def __getitem__(self, name):\n         \"\"\"Return a Media object that only contains media of the given type.\"\"\"\n@@ -116,115 +119,89 @@\n         return new\n \n     @staticmethod\n-    def merge(list_1, list_2):\n-        \"\"\"\n-        Merge two lists while trying to keep the relative order of the elements.\n-        Warn if the lists have the same two elements in a different relative\n-        order.\n-\n-        For static assets it can be important to have them included in the DOM\n-        in a certain order. In JavaScript you may not be able to reference a\n-        global or in CSS you might want to override a style.\n-        \"\"\"\n-        # Start with a copy of list_1.\n-        combined_list = list(list_1)\n-        last_insert_index = len(list_1)\n-        # Walk list_2 in reverse, inserting each element into combined_list if\n-        # it doesn't already exist.\n-        for path in reversed(list_2):\n-            try:\n-                # Does path already exist in the list?\n-                index = combined_list.index(path)\n-            except ValueError:\n-                # Add path to combined_list since it doesn't exist.\n-                combined_list.insert(last_insert_index, path)\n-            else:\n-                if index > last_insert_index:\n-                    warnings.warn(\n-                        'Detected duplicate Media files in an opposite order:\\n'\n-                        '%s\\n%s' % (combined_list[last_insert_index], combined_list[index]),\n-                        MediaOrderConflictWarning,\n-                    )\n-                # path already exists in the list. Update last_insert_index so\n-                # that the following elements are inserted in front of this one.\n-                last_insert_index = index\n-        return combined_list\n+    def merge(*lists):\n+        \"\"\"\n+        Merge lists of items, preserving order and removing duplicates. The\n+        order of items in each list is preserved, unless inserting an item\n+        from another list makes it impossible to do so.\n+        \"\"\"\n+        if not any(lists):\n+            return []\n+\n+        # A list of all items involved, in the order of their first appearance.\n+        all_items = list(OrderedDict.fromkeys(chain.from_iterable(lists)))\n+        # A map of each item to its first appearance (list_i, item_i).\n+        item_positions = {\n+            item: next(\n+                (list_i, item_i)\n+                for list_i, lst in enumerate(lists)\n+                for item_i, T in enumerate(lst)\n+                if T == item\n+            ) for item in all_items\n+        }\n+\n+        # A map of each item to a set of items that must come before it.\n+        dependencies = defaultdict(set)\n+        for lst in lists:\n+            for i, item in enumerate(lst[1:], 1):\n+                dependencies[item].add(lst[i - 1])\n+\n+        # The list of items that have been added to the merged list.\n+        merged = []\n+        # A list of items that have no dependencies or whose dependencies have\n+        # been satisfied.\n+        unblocked = []\n+\n+        def is_unblocked(item):\n+            \"\"\"An item is unblocked if all of its dependencies are in merged.\"\"\"\n+            return dependencies[item].issubset(merged)\n+\n+        # Initially, the unblocked items are the ones that have no dependencies.\n+        for item in all_items:\n+            if not dependencies[item]:\n+                unblocked.append(item)\n+\n+        # unblocked is a queue of items to be added to the merged list.\n+        # Items are sorted by their first appearance in the lists.\n+        unblocked.sort(key=lambda item: item_positions[item])\n+\n+        # A set of all items that have been added to the unblocked list.\n+        unblocked_set = set(unblocked)\n+\n+        while unblocked:\n+            # Pop the first item from the unblocked list and add it to the\n+            # merged list.\n+            item = unblocked.pop(0)\n+            merged.append(item)\n+\n+            # Find items that are now unblocked because item was their last\n+            # remaining dependency.\n+            newly_unblocked = []\n+            for other_item, other_dependencies in dependencies.items():\n+                if (\n+                    other_item not in unblocked_set and\n+                    other_item not in merged and\n+                    item in other_dependencies and\n+                    is_unblocked(other_item)\n+                ):\n+                    newly_unblocked.append(other_item)\n+\n+            if newly_unblocked:\n+                # Add the newly unblocked items to the unblocked list, keeping\n+                # it sorted.\n+                newly_unblocked.sort(key=lambda item: item_positions[item])\n+                for new_item in newly_unblocked:\n+                    # bisect.insort_left would be nice, but we can't use it\n+                    # because we're sorting by a key. This is O(n), but it's\n+                    # not a big deal because the list is short.\n+                    positions = item_positions[new_item]\n+                    for i, unblocked_item in enumerate(unblocked):\n+                        if item_positions[unblocked_item] > positions:\n+                            unblocked.insert(i, new_item)\n+                            break\n+                    else:\n+                        unblocked.append(new_item)\n+                    unblocked_set.add(new_item)\n+\n+        if len(merged) < len(all_items):\n+            # A cycle was detected. It's not possible to find a perfect\n+            # ordering, so we warn the user and add the remaining items in\n+            # order of their first appearance.\n+            remaining_items = set(all_items) - set(merged)\n+            # Find the items that are part of the cycle.\n+            offending_items = set()\n+            for item in remaining_items:\n+                for other_item in remaining_items:\n+                    if item in dependencies[other_item]:\n+                        offending_items.add(item)\n+                        offending_items.add(other_item)\n+            warnings.warn(\n+                'Detected duplicate Media files in an opposite order:\\n' +\n+                '\\n'.join(sorted(offending_items)),\n+                MediaOrderConflictWarning,\n+                stacklevel=2,\n+            )\n+            merged.extend(sorted(remaining_items, key=lambda item: item_positions[item]))\n+\n+        return merged\n \n \n class Widget(metaclass=MediaDefiningClass):\n\n```"}
{"instance_id": "django__django-11039", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/core/management/commands/sqlmigrate.py\n+++ b/django/core/management/commands/sqlmigrate.py\n@@ -69,7 +69,12 @@\n                     \"Cannot find a migration matching '%s' from app '%s'. Is it in \"\n                     \"INSTALLED_APPS?\" % (migration_name, app_label)\n                 ) from e\n-            self.output_transaction = migration.atomic\n+            # Wrap the SQL in a transaction only when the migration is declared\n+            # atomic *and* the connection supports rolling back DDL statements,\n+            # to match the behavior of the migration executor.\n+            self.output_transaction = (\n+                migration.atomic and connection.features.can_rollback_ddl\n+            )\n \n             # Make a plan that represents just the requested migration\n             # The executor will return a list of 2-tuples like [(self.migrationA, False),...],\n--- a/tests/migrations/test_commands.py\n+++ b/tests/migrations/test_commands.py\n@@ -370,6 +370,21 @@\n         self.assertNotIn(self.get_begin_sql(), output)\n         self.assertNotIn(self.get_commit_sql(), output)\n \n+    @mock.patch.object(connection.features, 'can_rollback_ddl', False)\n+    def test_sqlmigrate_for_non_transactional_databases(self):\n+        \"\"\"\n+        sqlmigrate doesn't wrap migrations in a transaction on databases that\n+        don't support transactional DDL.\n+        \"\"\"\n+        # Use a migration that is atomic.\n+        with override_settings(MIGRATION_MODULES={'migrations': 'migrations.test_migrations'}):\n+            out = io.StringIO()\n+            # The first migration is atomic.\n+            call_command('sqlmigrate', 'migrations', '0001', stdout=out)\n+            output = out.getvalue()\n+            self.assertNotIn(self.get_begin_sql(), output)\n+            self.assertNotIn(self.get_commit_sql(), output)\n+\n     @override_settings(INSTALLED_APPS=['migrations', 'django.contrib.auth', 'django.contrib.contenttypes'])\n     def test_sqlmigrate_app_with_no_migrations_module(self):\n         \"\"\"\n\n```"}
{"instance_id": "django__django-11049", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/contrib/admin/widgets.py\n+++ b/django/contrib/admin/widgets.py\n@@ -345,7 +345,7 @@\n \n             def get_context(self, name, value, attrs):\n                 context = super().get_context(name, value, attrs)\n-                context['widget']['format'] = _('[DD] [HH:[MM:]]ss[.uuuuuu]')\n+                context['widget']['format'] = _('[DD] [[HH:]MM:]ss[.uuuuuu]')\n                 return context\n \n \n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1862,13 +1862,17 @@\n class DurationField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value has an invalid format. It must be in \"\n-                     \"[DD] [HH:[MM:]]ss[.uuuuuu] format.\")\n+        'invalid': _(\n+            \"'%(value)s' value has an invalid format. It must be in \"\n+            \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\"\n+        ),\n     }\n     description = _(\"Duration\")\n \n     def formfield(self, **kwargs):\n         from django.forms import DurationField as DurationFormField\n-        defaults = {'form_class': DurationFormField}\n+        defaults = {\n+            'form_class': DurationFormField,\n+            'help_text': _('Enter a duration in [DD] [[HH:]MM:]ss[.uuuuuu] format.'),\n+        }\n         defaults.update(kwargs)\n         return super().formfield(**defaults)\n--- a/django/utils/dateparse.py\n+++ b/django/utils/dateparse.py\n@@ -102,7 +102,7 @@\n def parse_duration(value):\n     \"\"\"\n     Parse a duration string and return a datetime.timedelta.\n-    The format is ``[DD] [HH:[MM:]]ss[.uuuuuu]`` or ISO 8601 format.\n+    The format is ``[DD] [[HH:]MM:]ss[.uuuuuu]`` or ISO 8601 format.\n \n     Raise ValueError if the input is invalid.\n     \"\"\"\n\n```"}
{"instance_id": "django__django-11099", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/contrib/auth/validators.py\n+++ b/django/contrib/auth/validators.py\n@@ -7,7 +7,7 @@ from django.utils.translation import gettext_lazy as _\n \n @deconstructible\n class ASCIIUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only English letters, '\n         'numbers, and @/./+/-/_ characters.'\n@@ -17,7 +17,7 @@ class ASCIIUsernameValidator(validators.RegexValidator):\n \n @deconstructible\n class UnicodeUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only letters, '\n         'numbers, and @/./+/-/_ characters.'\n\n```"}
{"instance_id": "django__django-11133", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -246,9 +246,9 @@\n class HttpResponseBase:\n     def make_bytes(self, value):\n         \"\"\"Turn a value into a bytestring encoded in the output charset.\"\"\"\n-        # Handle non-string types\n-        if isinstance(value, bytes):\n-            return value\n+        # Handle bytes-like types\n+        if isinstance(value, (bytes, memoryview)):\n+            return bytes(value)\n         if isinstance(value, str):\n             # If the value is a string, encode it using the response charset.\n             return value.encode(self.charset)\n@@ -321,7 +321,7 @@\n     @content.setter\n     def content(self, value):\n         # Consume iterators upon assignment to allow repeated iteration.\n-        if hasattr(value, \"__iter__\") and not isinstance(value, (bytes, str)):\n+        if hasattr(value, \"__iter__\") and not isinstance(value, (bytes, str, memoryview)):\n             content = b\"\".join(self.make_bytes(chunk) for chunk in value)\n             if hasattr(value, \"close\"):\n                 try:\n\n```"}
{"instance_id": "django__django-11179", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,6 +277,7 @@ class Collector:\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n\n```"}
{"instance_id": "django__django-11283", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n+++ b/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n@@ -22,12 +22,23 @@\n         ]\n         permissions_query = Q(codename__in=proxy_default_permissions_codenames)\n         for codename, name in opts.permissions:\n             permissions_query = permissions_query | Q(codename=codename)\n         concrete_content_type = ContentType.objects.get_for_model(Model, for_concrete_model=True)\n         proxy_content_type = ContentType.objects.get_for_model(Model, for_concrete_model=False)\n         old_content_type = proxy_content_type if reverse else concrete_content_type\n         new_content_type = concrete_content_type if reverse else proxy_content_type\n-        Permission.objects.filter(\n+        # In case of a stale content type, a permission with the same\n+        # codename may already exist for the proxy model.\n+        permissions_to_update = Permission.objects.filter(\n             permissions_query,\n             content_type=old_content_type,\n-        ).update(content_type=new_content_type)\n+        )\n+        for permission in permissions_to_update:\n+            if Permission.objects.filter(\n+                codename=permission.codename, content_type=new_content_type,\n+            ).exists():\n+                # A permission with the same codename already exists for the\n+                # proxy model, so delete the permission for the concrete model.\n+                permission.delete()\n+            else:\n+                permission.content_type = new_content_type\n+                permission.save(using=schema_editor.connection.alias)\n         if verbosity >= 2:\n             for Model in apps.get_models():\n                 opts = Model._meta\n\n```"}
{"instance_id": "django__django-11422", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -198,7 +198,14 @@\n         # handle this.\n         spec = getattr(module, \"__spec__\", None)\n         if spec is None:\n-            continue\n+            # This can happen for __main__ & built-in modules.\n+            if getattr(module, '__name__', None) == '__main__':\n+                # __main__ can be a module, a script, or interactive session.\n+                # The latter cannot be reloaded.\n+                if hasattr(module, '__file__'):\n+                    yield Path(module.__file__)\n+            continue\n         # We're only interested in files that can be watched.\n         if not spec.has_location:\n             continue\n\n```"}
{"instance_id": "django__django-11564", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/core/files/storage.py\n+++ b/django/core/files/storage.py\n@@ -6,6 +6,7 @@\n from urllib.parse import urljoin\n \n from django.conf import settings\n+from django.urls import get_script_prefix\n from django.core.exceptions import SuspiciousOperation\n from django.utils._os import abspathu, safe_join\n from django.utils.deconstruct import deconstructible\n@@ -112,7 +113,13 @@\n     def url(self, name):\n         if self.base_url is None:\n             raise ValueError(\"This file is not accessible via a URL.\")\n-        return urljoin(self.base_url, filepath_to_uri(name))\n+        url = urljoin(self.base_url, filepath_to_uri(name))\n+        # If the URL is relative, prefix it with SCRIPT_NAME.\n+        if url.startswith('/') and not url.startswith('//'):\n+            script_prefix = get_script_prefix()\n+            if not url.startswith(script_prefix):\n+                url = '%s%s' % (script_prefix.rstrip('/'), url)\n+        return url\n \n     def _save(self, name, content):\n         full_path = self.path(name)\n--- a/django/templatetags/static.py\n+++ b/django/templatetags/static.py\n@@ -2,6 +2,7 @@\n \n from django import template\n from django.conf import settings\n+from django.urls import get_script_prefix\n from django.utils.encoding import iri_to_uri\n \n register = template.Library()\n@@ -53,7 +54,13 @@\n     def handle_simple(path):\n         if settings.DEBUG:\n             # ...\n-        return urljoin(settings.STATIC_URL, quote(path))\n+        url = urljoin(settings.STATIC_URL, quote(path))\n+        # If the URL is relative, prefix it with SCRIPT_NAME.\n+        if url.startswith('/') and not url.startswith('//'):\n+            script_prefix = get_script_prefix()\n+            if not url.startswith(script_prefix):\n+                url = '%s%s' % (script_prefix.rstrip('/'), url)\n+        return url\n \n \n def static(path):\n@@ -63,7 +70,13 @@\n     \"\"\"\n     if settings.DEBUG:\n         # ...\n-    return urljoin(settings.STATIC_URL, quote(path))\n+    url = urljoin(settings.STATIC_URL, quote(path))\n+    # If the URL is relative, prefix it with SCRIPT_NAME.\n+    if url.startswith('/') and not url.startswith('//'):\n+        script_prefix = get_script_prefix()\n+        if not url.startswith(script_prefix):\n+            url = '%s%s' % (script_prefix.rstrip('/'), url)\n+    return url\n \n \n @register.tag('static')\n\n```"}
{"instance_id": "django__django-11583", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -129,7 +129,13 @@\n                     # A path has an embedded null byte.\n                     continue\n             else:\n-                results.add(path.resolve().absolute())\n+                # The path is already a Path object.\n+                try:\n+                    results.add(path.resolve().absolute())\n+                except (ValueError, FileNotFoundError):\n+                    # path.resolve() may raise ValueError on some platforms if the\n+                    # path contains an embedded null byte, or FileNotFoundError\n+                    # if the path is a broken symlink.\n+                    pass\n         return frozenset(results)\n \n \n\n```"}
{"instance_id": "django__django-11620", "model_name_or_path": "parallelsynthetize_router", "model_patch": "```diff\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -5,7 +5,7 @@\n from pathlib import Path\n \n from django.conf import settings\n-from django.http import HttpResponse, HttpResponseNotFound\n+from django.http import Http404, HttpResponse, HttpResponseNotFound\n from django.template import Context, Engine, TemplateDoesNotExist\n from django.template.defaultfilters import pprint\n from django.urls import Resolver404, resolve\n@@ -483,7 +483,7 @@\n     caller = ''\n     try:\n         resolver_match = resolve(request.path_info)\n-    except Resolver404:\n+    except (Resolver404, Http404):\n         pass\n     else:\n         obj = resolver_match.func\n\n```"}
